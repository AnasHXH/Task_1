{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798923f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be146ce0",
   "metadata": {},
   "source": [
    "# Training decomposition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a84c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/akoubaa/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Training on device: cuda:0\n",
      "\n",
      "Applying Class Decomposition to balance the dataset...\n",
      "Extracting features to split Pneumonia into 2 clusters using CLIP...\n",
      "/home/akoubaa/anaconda3/envs/OSEDiff/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at openai/clip-vit-base-patch32 were not used when initializing CLIPVisionModel: ['text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.9.mlp.fc2.bias', 'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.6.mlp.fc2.bias', 'text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_model.encoder.layers.5.mlp.fc1.weight', 'text_model.encoder.layers.0.self_attn.k_proj.weight', 'text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.9.mlp.fc2.weight', 'text_model.encoder.layers.1.self_attn.v_proj.weight', 'text_model.encoder.layers.7.mlp.fc1.weight', 'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.4.layer_norm1.bias', 'text_model.encoder.layers.7.layer_norm1.bias', 'text_model.encoder.layers.6.layer_norm2.weight', 'text_model.encoder.layers.3.mlp.fc2.bias', 'text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_model.encoder.layers.8.mlp.fc2.weight', 'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.8.mlp.fc1.weight', 'text_model.encoder.layers.1.layer_norm2.weight', 'text_model.encoder.layers.9.layer_norm1.bias', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.10.mlp.fc2.weight', 'text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_model.encoder.layers.9.layer_norm1.weight', 'text_model.encoder.layers.5.layer_norm1.weight', 'text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_model.encoder.layers.0.self_attn.q_proj.weight', 'text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_model.encoder.layers.4.self_attn.q_proj.bias', 'text_model.encoder.layers.7.layer_norm2.bias', 'text_model.encoder.layers.10.mlp.fc1.weight', 'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_model.encoder.layers.1.self_attn.out_proj.weight', 'text_model.encoder.layers.10.self_attn.out_proj.bias', 'text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_model.embeddings.position_ids', 'text_model.encoder.layers.8.mlp.fc2.bias', 'text_model.encoder.layers.6.layer_norm2.bias', 'text_model.encoder.layers.6.layer_norm1.weight', 'text_model.encoder.layers.10.self_attn.k_proj.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_model.encoder.layers.5.self_attn.k_proj.weight', 'text_model.encoder.layers.7.layer_norm2.weight', 'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.5.layer_norm2.weight', 'text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_model.encoder.layers.3.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.10.layer_norm2.weight', 'text_model.encoder.layers.2.self_attn.out_proj.bias', 'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.encoder.layers.2.mlp.fc2.bias', 'text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_model.encoder.layers.1.layer_norm1.weight', 'text_model.encoder.layers.2.mlp.fc1.bias', 'text_model.encoder.layers.9.layer_norm2.weight', 'text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_model.encoder.layers.5.mlp.fc2.bias', 'text_model.encoder.layers.8.layer_norm1.weight', 'text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_model.encoder.layers.0.layer_norm2.weight', 'text_model.encoder.layers.5.layer_norm2.bias', 'logit_scale', 'text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_model.encoder.layers.0.self_attn.out_proj.weight', 'text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.0.layer_norm1.weight', 'text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_model.encoder.layers.1.self_attn.q_proj.weight', 'text_model.encoder.layers.1.mlp.fc2.bias', 'text_model.encoder.layers.3.layer_norm2.bias', 'text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_model.encoder.layers.8.layer_norm1.bias', 'text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.6.self_attn.out_proj.bias', 'text_model.encoder.layers.7.self_attn.out_proj.bias', 'text_model.encoder.layers.8.mlp.fc1.bias', 'text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.4.layer_norm2.bias', 'text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_model.encoder.layers.1.mlp.fc2.weight', 'text_model.final_layer_norm.weight', 'text_model.encoder.layers.3.mlp.fc1.bias', 'text_model.encoder.layers.7.mlp.fc2.weight', 'text_model.encoder.layers.8.self_attn.out_proj.bias', 'text_model.encoder.layers.6.mlp.fc2.weight', 'text_model.encoder.layers.5.layer_norm1.bias', 'text_model.encoder.layers.0.self_attn.v_proj.weight', 'text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_model.encoder.layers.5.self_attn.v_proj.weight', 'text_model.encoder.layers.9.self_attn.v_proj.weight', 'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.4.mlp.fc2.bias', 'text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.10.layer_norm1.weight', 'text_model.encoder.layers.5.self_attn.v_proj.bias', 'text_model.encoder.layers.3.self_attn.out_proj.bias', 'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.0.mlp.fc2.bias', 'text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_model.embeddings.token_embedding.weight', 'text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.encoder.layers.2.layer_norm1.bias', 'text_model.encoder.layers.6.mlp.fc1.bias', 'text_model.final_layer_norm.bias', 'text_model.encoder.layers.3.self_attn.k_proj.bias', 'text_model.encoder.layers.2.mlp.fc2.weight', 'text_projection.weight', 'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.10.self_attn.v_proj.bias', 'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.6.mlp.fc1.weight', 'text_model.encoder.layers.6.layer_norm1.bias', 'text_model.encoder.layers.6.self_attn.v_proj.bias', 'text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_model.encoder.layers.8.layer_norm2.bias', 'text_model.encoder.layers.1.self_attn.k_proj.weight', 'text_model.encoder.layers.1.mlp.fc1.weight', 'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_model.encoder.layers.0.mlp.fc2.weight', 'text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.embeddings.position_embedding.weight', 'text_model.encoder.layers.10.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_model.encoder.layers.3.layer_norm1.bias', 'text_model.encoder.layers.9.layer_norm2.bias', 'text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_model.encoder.layers.9.self_attn.out_proj.bias', 'text_model.encoder.layers.7.mlp.fc1.bias', 'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.encoder.layers.4.mlp.fc1.bias', 'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_model.encoder.layers.4.self_attn.out_proj.bias', 'text_model.encoder.layers.7.layer_norm1.weight', 'text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_model.encoder.layers.9.mlp.fc1.weight', 'text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_model.encoder.layers.4.self_attn.k_proj.bias', 'text_model.encoder.layers.7.mlp.fc2.bias', 'text_model.encoder.layers.2.layer_norm1.weight', 'visual_projection.weight', 'text_model.encoder.layers.8.self_attn.q_proj.weight', 'text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.encoder.layers.9.mlp.fc1.bias', 'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.0.mlp.fc1.weight', 'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.2.layer_norm2.bias', 'text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_model.encoder.layers.5.mlp.fc1.bias', 'text_model.encoder.layers.2.self_attn.k_proj.bias', 'text_model.encoder.layers.8.layer_norm2.weight', 'text_model.encoder.layers.5.mlp.fc2.weight', 'text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_model.encoder.layers.5.self_attn.out_proj.bias']\n",
      "- This IS expected if you are initializing CLIPVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Extracting Features: 100%|██████████████████| 3494/3494 [00:44<00:00, 79.25it/s]\n",
      "Running K-Means clustering...\n",
      "Decomposition complete! New distribution: {'Normal': 1214, 'Pneumonia_Type_1': 1937, 'Pneumonia_Type_2': 1557}\n",
      "\n",
      "/home/akoubaa/anaconda3/envs/OSEDiff/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Starting training for 32 epochs...\n",
      "Epoch 1/32 [Train]: 100%|███████████████████| 1177/1177 [01:59<00:00,  9.86it/s]\n",
      "Epoch 1/32 [Val]: 100%|███████████████████████| 131/131 [00:04<00:00, 30.79it/s]\n",
      "Train Loss: 0.5643 Acc: 0.7073 | Val Loss: 0.1767 Acc: 0.9313\n",
      "Epoch 2/32 [Train]: 100%|███████████████████| 1177/1177 [02:00<00:00,  9.75it/s]\n",
      "Epoch 2/32 [Val]: 100%|███████████████████████| 131/131 [00:04<00:00, 30.82it/s]\n",
      "Train Loss: 0.4116 Acc: 0.7808 | Val Loss: 0.1225 Acc: 0.9599\n",
      "Epoch 3/32 [Train]: 100%|███████████████████| 1177/1177 [01:59<00:00,  9.89it/s]\n",
      "Epoch 3/32 [Val]: 100%|███████████████████████| 131/131 [00:04<00:00, 29.58it/s]\n",
      "Train Loss: 0.3682 Acc: 0.8016 | Val Loss: 0.3892 Acc: 0.8664\n",
      "Epoch 4/32 [Train]: 100%|███████████████████| 1177/1177 [01:58<00:00,  9.91it/s]\n",
      "Epoch 4/32 [Val]: 100%|███████████████████████| 131/131 [00:04<00:00, 30.91it/s]\n",
      "Train Loss: 0.3458 Acc: 0.8080 | Val Loss: 0.1359 Acc: 0.9370\n",
      "Epoch 5/32 [Train]: 100%|███████████████████| 1177/1177 [02:00<00:00,  9.75it/s]\n",
      "Epoch 5/32 [Val]: 100%|███████████████████████| 131/131 [00:04<00:00, 31.42it/s]\n",
      "Train Loss: 0.3278 Acc: 0.8233 | Val Loss: 0.1104 Acc: 0.9561\n",
      "Epoch 6/32 [Train]: 100%|███████████████████| 1177/1177 [02:00<00:00,  9.79it/s]\n",
      "Epoch 6/32 [Val]: 100%|███████████████████████| 131/131 [00:04<00:00, 32.48it/s]\n",
      "Train Loss: 0.3121 Acc: 0.8320 | Val Loss: 0.1121 Acc: 0.9542\n",
      "Epoch 7/32 [Train]: 100%|███████████████████| 1177/1177 [02:02<00:00,  9.58it/s]\n",
      "Epoch 7/32 [Val]: 100%|███████████████████████| 131/131 [00:04<00:00, 29.03it/s]\n",
      "Train Loss: 0.3072 Acc: 0.8282 | Val Loss: 0.0604 Acc: 0.9790\n",
      "Epoch 8/32 [Train]: 100%|███████████████████| 1177/1177 [02:01<00:00,  9.67it/s]\n",
      "Epoch 8/32 [Val]: 100%|███████████████████████| 131/131 [00:04<00:00, 29.87it/s]\n",
      "Train Loss: 0.2901 Acc: 0.8443 | Val Loss: 0.0811 Acc: 0.9676\n",
      "Epoch 9/32 [Train]: 100%|███████████████████| 1177/1177 [02:04<00:00,  9.46it/s]\n",
      "Epoch 9/32 [Val]: 100%|███████████████████████| 131/131 [00:04<00:00, 32.56it/s]\n",
      "Train Loss: 0.2869 Acc: 0.8403 | Val Loss: 0.1193 Acc: 0.9561\n",
      "Epoch 10/32 [Train]: 100%|██████████████████| 1177/1177 [02:00<00:00,  9.79it/s]\n",
      "Epoch 10/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 29.76it/s]\n",
      "Train Loss: 0.2880 Acc: 0.8398 | Val Loss: 0.0890 Acc: 0.9618\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 11/32 [Train]: 100%|██████████████████| 1177/1177 [02:01<00:00,  9.67it/s]\n",
      "Epoch 11/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 27.90it/s]\n",
      "Train Loss: 0.2296 Acc: 0.8740 | Val Loss: 0.0733 Acc: 0.9714\n",
      "Epoch 12/32 [Train]: 100%|██████████████████| 1177/1177 [02:02<00:00,  9.63it/s]\n",
      "Epoch 12/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 27.19it/s]\n",
      "Train Loss: 0.2143 Acc: 0.8853 | Val Loss: 0.0948 Acc: 0.9676\n",
      "Epoch 13/32 [Train]: 100%|██████████████████| 1177/1177 [02:00<00:00,  9.77it/s]\n",
      "Epoch 13/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 29.43it/s]\n",
      "Train Loss: 0.1933 Acc: 0.8946 | Val Loss: 0.0868 Acc: 0.9637\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 14/32 [Train]: 100%|██████████████████| 1177/1177 [02:00<00:00,  9.78it/s]\n",
      "Epoch 14/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 30.31it/s]\n",
      "Train Loss: 0.1890 Acc: 0.8938 | Val Loss: 0.0895 Acc: 0.9714\n",
      "Epoch 15/32 [Train]: 100%|██████████████████| 1177/1177 [01:59<00:00,  9.84it/s]\n",
      "Epoch 15/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 31.31it/s]\n",
      "Train Loss: 0.1883 Acc: 0.8970 | Val Loss: 0.0811 Acc: 0.9695\n",
      "Epoch 16/32 [Train]: 100%|██████████████████| 1177/1177 [01:59<00:00,  9.88it/s]\n",
      "Epoch 16/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 32.09it/s]\n",
      "Train Loss: 0.1836 Acc: 0.8968 | Val Loss: 0.0974 Acc: 0.9637\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 17/32 [Train]: 100%|██████████████████| 1177/1177 [02:07<00:00,  9.21it/s]\n",
      "Epoch 17/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 31.19it/s]\n",
      "Train Loss: 0.1845 Acc: 0.8976 | Val Loss: 0.0866 Acc: 0.9676\n",
      "Epoch 18/32 [Train]: 100%|██████████████████| 1177/1177 [02:05<00:00,  9.41it/s]\n",
      "Epoch 18/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 30.09it/s]\n",
      "Train Loss: 0.1776 Acc: 0.9002 | Val Loss: 0.0804 Acc: 0.9714\n",
      "Epoch 19/32 [Train]: 100%|██████████████████| 1177/1177 [02:07<00:00,  9.24it/s]\n",
      "Epoch 19/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 31.48it/s]\n",
      "Train Loss: 0.1791 Acc: 0.8983 | Val Loss: 0.0902 Acc: 0.9676\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 20/32 [Train]: 100%|██████████████████| 1177/1177 [02:04<00:00,  9.47it/s]\n",
      "Epoch 20/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 32.52it/s]\n",
      "Train Loss: 0.1783 Acc: 0.8991 | Val Loss: 0.0898 Acc: 0.9695\n",
      "Epoch 21/32 [Train]: 100%|██████████████████| 1177/1177 [02:01<00:00,  9.68it/s]\n",
      "Epoch 21/32 [Val]: 100%|██████████████████████| 131/131 [00:04<00:00, 32.04it/s]\n",
      "Train Loss: 0.1818 Acc: 0.8961 | Val Loss: 0.0861 Acc: 0.9676\n",
      "Epoch 22/32 [Train]: 100%|██████████████████| 1177/1177 [01:51<00:00, 10.59it/s]\n",
      "Epoch 22/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 34.41it/s]\n",
      "Train Loss: 0.1840 Acc: 0.8974 | Val Loss: 0.0857 Acc: 0.9733\n",
      "Epoch 23/32 [Train]: 100%|██████████████████| 1177/1177 [01:40<00:00, 11.67it/s]\n",
      "Epoch 23/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 34.49it/s]\n",
      "Train Loss: 0.1868 Acc: 0.8961 | Val Loss: 0.0860 Acc: 0.9714\n",
      "Epoch 24/32 [Train]: 100%|██████████████████| 1177/1177 [01:47<00:00, 10.98it/s]\n",
      "Epoch 24/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 33.60it/s]\n",
      "Train Loss: 0.1769 Acc: 0.8974 | Val Loss: 0.0829 Acc: 0.9714\n",
      "Epoch 25/32 [Train]: 100%|██████████████████| 1177/1177 [01:44<00:00, 11.30it/s]\n",
      "Epoch 25/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 34.72it/s]\n",
      "Train Loss: 0.1829 Acc: 0.8980 | Val Loss: 0.0887 Acc: 0.9676\n",
      "Epoch 26/32 [Train]: 100%|██████████████████| 1177/1177 [01:44<00:00, 11.29it/s]\n",
      "Epoch 26/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 32.76it/s]\n",
      "Train Loss: 0.1857 Acc: 0.8944 | Val Loss: 0.0992 Acc: 0.9656\n",
      "Epoch 27/32 [Train]: 100%|██████████████████| 1177/1177 [01:48<00:00, 10.89it/s]\n",
      "Epoch 27/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 34.98it/s]\n",
      "Train Loss: 0.1813 Acc: 0.8983 | Val Loss: 0.0892 Acc: 0.9714\n",
      "Epoch 28/32 [Train]: 100%|██████████████████| 1177/1177 [01:44<00:00, 11.28it/s]\n",
      "Epoch 28/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 33.92it/s]\n",
      "Train Loss: 0.1852 Acc: 0.8915 | Val Loss: 0.0893 Acc: 0.9656\n",
      "Epoch 29/32 [Train]: 100%|██████████████████| 1177/1177 [01:43<00:00, 11.33it/s]\n",
      "Epoch 29/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 34.10it/s]\n",
      "Train Loss: 0.1746 Acc: 0.8993 | Val Loss: 0.0812 Acc: 0.9695\n",
      "Epoch 30/32 [Train]: 100%|██████████████████| 1177/1177 [01:50<00:00, 10.68it/s]\n",
      "Epoch 30/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 33.77it/s]\n",
      "Train Loss: 0.1790 Acc: 0.8989 | Val Loss: 0.0956 Acc: 0.9676\n",
      "Epoch 31/32 [Train]: 100%|██████████████████| 1177/1177 [01:45<00:00, 11.12it/s]\n",
      "Epoch 31/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 33.15it/s]\n",
      "Train Loss: 0.1809 Acc: 0.8985 | Val Loss: 0.0871 Acc: 0.9714\n",
      "Epoch 32/32 [Train]: 100%|██████████████████| 1177/1177 [01:42<00:00, 11.45it/s]\n",
      "Epoch 32/32 [Val]: 100%|██████████████████████| 131/131 [00:03<00:00, 33.78it/s]\n",
      "Train Loss: 0.1797 Acc: 0.8983 | Val Loss: 0.0804 Acc: 0.9733\n",
      "Training complete. Best Validation Accuracy: 0.9790\n",
      "Model and curves saved to /media/akoubaa/MySSD/home/anas/Anas_CODES/tasks/task_1/results_decom\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python train_decomposition.py\\\n",
    "     --data_dir pneumoniamnist_dataset\\\n",
    "         --output_dir results_decom\\\n",
    "             --batch_size 4 --epochs 32 --learning_rate 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25453e2e",
   "metadata": {},
   "source": [
    "# Inference and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100c687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/akoubaa/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Evaluating on device: cuda:0\n",
      "/home/akoubaa/anaconda3/envs/OSEDiff/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/akoubaa/anaconda3/envs/OSEDiff/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Running inference on test set with Binary Mapping...\n",
      "--- Final Evaluation Metrics (Decomposition Applied) ---\n",
      "Accuracy:  0.8862\n",
      "Precision: 0.8988\n",
      "Recall:    0.8862\n",
      "F1-Score:  0.8816\n",
      "AUC:       0.9761\n",
      "\n",
      "--- Detailed Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.98      0.71      0.82       234\n",
      "   Pneumonia       0.85      0.99      0.92       390\n",
      "\n",
      "    accuracy                           0.89       624\n",
      "   macro avg       0.91      0.85      0.87       624\n",
      "weighted avg       0.90      0.89      0.88       624\n",
      "\n",
      "\n",
      "Extracting failure cases...\n",
      "Evaluation complete. All visualizations and metrics saved to /media/akoubaa/MySSD/home/anas/Anas_CODES/tasks/task_1/results_test_decom\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_decomp.py\\\n",
    "     --data_dir pneumoniamnist_dataset\\\n",
    "         --model_path results_decom/best_model.pth\\\n",
    "             --output_dir results_test_decom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSEDiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
